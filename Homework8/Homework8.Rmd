---
title: "Homework 8"
author: "Han Nguyen - TXN200004"
date: "11/25/2025"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1

## Simulate data from simple linear model

```{r, problem1_simulate}
# Set seed for reproducibility
set.seed(1)

# Create x values (arithmetic sequence from 1 to 100)
x <- 1:100

# Simulate errors from N(0, 6^2)
epsilon <- rnorm(100, mean = 0, sd = 6)

# Generate y values: Y = 1 + 2x + epsilon
y <- 1 + 2*x + epsilon
```

## Scatter plot with regression line

```{r, problem1_plot}
# Fit linear regression model
model <- lm(y ~ x)

# Create scatter plot with regression line
plot(x, y,
     main = "Scatter Plot with Regression Line",
     xlab = "x",
     ylab = "y",
     pch = 16,
     col = "blue")
abline(model, col = "red", lwd = 2)
```

## Hypothesis Test (7-Step Procedure)

**Step 1: State the null and alternative hypotheses**

- $H_0: \beta_1 = 2$
- $H_a: \beta_1 \neq 2$

**Step 2: Choose the significance level**

$\alpha = 0.05$

**Step 3: Determine the appropriate test statistic**

```{r, problem1_test}
# Get model summary
summary_model <- summary(model)
beta1_hat <- coef(model)[2]
se_beta1 <- summary_model$coefficients[2, 2]
n <- length(y)
df <- n - 2
```

The appropriate test statistic for testing the slope coefficient is:
$$t = \frac{\hat{\beta}_1 - \beta_{1,0}}{SE(\hat{\beta}_1)}$$

which follows a $t$-distribution with $n-2 = `r df`$ degrees of freedom under $H_0$.

**Step 4: Formulate the decision rule**

```{r, problem1_critical}
# Calculate critical value
t_critical <- qt(0.975, df)
```

Decision rule: Reject $H_0$ if $|t| > t_{\alpha/2, n-2} = `r round(t_critical, 4)`$ or if p-value $< \alpha = 0.05$.

**Step 5: Collect data and calculate the test statistic**

```{r, problem1_compute}
# Calculate test statistic
t_stat <- (beta1_hat - 2) / se_beta1
```

Using our simulated sample data:

- $\hat{\beta}_1 = `r round(beta1_hat, 4)`$
- $SE(\hat{\beta}_1) = `r round(se_beta1, 4)`$
- $t = \frac{`r round(beta1_hat, 4)` - 2}{`r round(se_beta1, 4)`} = `r round(t_stat, 4)`$

**Step 6: Make a decision**

```{r, problem1_decision}
# Calculate p-value
p_value <- 2 * pt(abs(t_stat), df, lower.tail = FALSE)
decision <- ifelse(abs(t_stat) > t_critical, "reject", "fail to reject")
```

Since $|t| = `r round(abs(t_stat), 4)`$ is `r ifelse(abs(t_stat) > t_critical, "greater", "less")` than the critical value $`r round(t_critical, 4)`$, and the p-value is $`r round(p_value, 4)`$ which is `r ifelse(p_value < 0.05, "less", "greater")` than $\alpha = 0.05$, we **`r decision`** $H_0$.

**Step 7: Draw a conclusion**

We `r decision` $H_0$. At the 5% significance level, there is `r ifelse(p_value < 0.05, "sufficient", "insufficient")` evidence to conclude that the true slope $\beta_1$ is different from 2.

# Problem 2

## Create the Dallas homes dataset

```{r, problem2_data}
# Create the dataset
price <- c(300000, 250000, 400000, 550000, 317000, 389000, 425000, 289000, 389000)
bedrooms <- c(3, 3, 4, 5, 4, 3, 6, 3, 4)
```

## Scatter plot with regression line

```{r, problem2_plot}
# Fit linear regression model
model2 <- lm(price ~ bedrooms)

# Create scatter plot with regression line
plot(bedrooms, price,
     main = "Home Price vs. Number of Bedrooms",
     xlab = "Number of Bedrooms",
     ylab = "Price (USD)",
     pch = 16,
     col = "blue",
     cex = 1.5)
abline(model2, col = "red", lwd = 2)

# Display regression equation
coeffs <- coef(model2)
text(4.5, 500000,
     paste0("Price = ", round(coeffs[1], 0), " + ", round(coeffs[2], 0), " × Bedrooms"),
     col = "red")
```

## Confidence intervals for mean price

```{r, problem2_predict}
# Create new data for bedrooms 2 to 8
new_data <- data.frame(bedrooms = 2:8)

# Compute confidence intervals for mean price
predictions <- predict(model2, newdata = new_data, interval = "confidence", level = 0.95)

# Combine with bedroom numbers for display
results <- cbind(new_data, predictions)
colnames(results) <- c("Bedrooms", "Predicted Price", "Lower 95% CI", "Upper 95% CI")

# Display results
knitr::kable(results, format = "markdown", digits = 0)
```

The table above shows the predicted mean price and 95% confidence intervals for homes with 2 to 8 bedrooms in Dallas.

# Problem 3

## Load data and fit regression model

```{r, problem3_data}
# Load the UsingR package
library(UsingR)

# Load the deflection dataset
data(deflection)

# Fit linear regression model: Deflection ~ Load
model3 <- lm(Deflection ~ Load, data = deflection)

# Display model summary
summary(model3)
```

## Scatter plot with regression line

```{r, problem3_plot}
# Create scatter plot with regression line
plot(deflection$Load, deflection$Deflection,
     main = "Deflection vs. Load",
     xlab = "Load",
     ylab = "Deflection",
     pch = 16,
     col = "blue",
     cex = 1.5)
abline(model3, col = "red", lwd = 2)

# Add regression equation to plot
coeffs3 <- coef(model3)
text(x = mean(deflection$Load),
     y = max(deflection$Deflection),
     paste0("Deflection = ", round(coeffs3[1], 4), " + ", round(coeffs3[2], 4), " × Load"),
     col = "red")
```

## 95% Confidence Intervals for $\beta_0$ and $\beta_1$

```{r, problem3_ci}
# Compute 95% confidence intervals for regression coefficients
ci <- confint(model3, level = 0.95)

# Display confidence intervals
ci
```

The 95% confidence intervals are:

- **$\beta_0$ (Intercept)**: [`r round(ci[1,1], 6)`, `r round(ci[1,2], 6)`]
- **$\beta_1$ (Slope)**: [`r format(ci[2,1], scientific = TRUE, digits = 4)`, `r format(ci[2,2], scientific = TRUE, digits = 4)`]

This means we are 95% confident that the true intercept $\beta_0$ lies between `r round(ci[1,1], 6)` and `r round(ci[1,2], 6)`, and the true slope $\beta_1$ lies between `r format(ci[2,1], scientific = TRUE, digits = 4)` and `r format(ci[2,2], scientific = TRUE, digits = 4)`. The slope is very small, indicating that each unit increase in Load corresponds to a very small increase in Deflection.
